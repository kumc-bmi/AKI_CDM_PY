{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868d9b2e-f61c-427a-81e9-be41d341a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from skopt import BayesSearchCV\n",
    "from catboost import Pool, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3568dcf-fd02-49f4-8987-b988956b89db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgbHalvingGridSearchCV(X_train, y_train):\n",
    "    labelcount = y_train.value_counts()\n",
    "    params = {\n",
    "            'subsample': [0.5, 1], #subsample data set with grow tree\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "            'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'max_depth': [5, 10],\n",
    "            'learning_rate': [0.01, 0.1, 0.5],\n",
    "            'gamma' :[0.5, 1]        \n",
    "            }\n",
    "\n",
    "    #scale_pos_weight for imbalanced data\n",
    "    cvmodel = XGBClassifier(n_jobs=1, scale_pos_weight=labelcount[0]/labelcount[1], \n",
    "                            objective='binary:logistic', eval_metric='auc', verbosity=0, \n",
    "                            early_stopping_rounds=50, use_label_encoder=False)\n",
    "\n",
    "    # skf = StratifiedKFold(n_splits=5)\n",
    "    # random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=n_trial, scoring='roc_auc', n_jobs=n_trial, cv=skf.split(X_train_onehot_com,y_train_com), verbose=3, random_state=1001)\n",
    "    # random_search.fit(X_train_onehot_com, y_train_com)\n",
    "\n",
    "    from sklearn.experimental import enable_halving_search_cv\n",
    "    from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "    #search_obj = HalvingGridSearchCV(cvmodel, params, verbose=3, n_jobs=23)\n",
    "    search_obj = HalvingGridSearchCV(cvmodel, params, verbose=3, n_jobs=20, resource='n_estimators', max_resources=2000, min_resources=100, aggressive_elimination=True)\n",
    "    search_result = search_obj.fit(X_train, y_train)\n",
    "    bestmodel = search_result.best_estimator_\n",
    "    bestmodel.set_params(n_jobs=23)\n",
    "    return bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d98ded8-01f2-4615-a881-ffa2855b3a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgbBayesSearchCV(X_train, y_train):\n",
    "    labelcount = y_train.value_counts()\n",
    "    cvmodel = XGBClassifier(n_jobs=4, scale_pos_weight=labelcount[0]/labelcount[1], \n",
    "                            objective='binary:logistic', eval_metric='auc', verbosity=0, \n",
    "    #                        early_stopping_rounds=50, n_estimators=1000, use_label_encoder=False)\n",
    "                            early_stopping_rounds=50, use_label_encoder=False)\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'max_depth': (0, 50),\n",
    "        'max_delta_step': (0, 20),    \n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': (0.01, 1.0, 'uniform'),    \n",
    "        'gamma': (1e-9, 1.0, 'log-uniform'),\n",
    "        'n_estimators': (50, 1000),\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    bayes_cv_tuner = BayesSearchCV(estimator=cvmodel, search_spaces=params, cv=skf, n_jobs=5, verbose=3, refit = True, n_iter=50)\n",
    "    bayes_cv_tuner.fit(X_train, y_train)\n",
    "    bestmodel = bayes_cv_tuner.best_estimator_\n",
    "    bestmodel.set_params(n_jobs=23)\n",
    "    return bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f794556-d361-4a78-888a-e4ce6b7b0f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def catDefault(X_train, y_train):\n",
    "    labelcount = y_train.value_counts()    \n",
    "    cat_features = list(X_train.select_dtypes('bool').columns)\n",
    "    cvmodel = CatBoostClassifier(scale_pos_weight=labelcount[0]/labelcount[1], \n",
    "                            objective='Logloss', eval_metric='AUC', verbose=50,\n",
    "                            early_stopping_rounds=50, cat_features=cat_features,\n",
    "                            custom_metric=['Logloss', 'AUC:hints=skip_train~false'])\n",
    "    return cvmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a2739cf-4a0b-4842-9098-ad616b25b260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def catRandomSearch(X_train, y_train):\n",
    "    labelcount = y_train.value_counts()    \n",
    "    cvmodel = CatBoostClassifier(scale_pos_weight=labelcount[0]/labelcount[1], \n",
    "                            objective='Logloss', eval_metric='AUC:hints=skip_train~false', verbose=50, \n",
    "                            early_stopping_rounds=50)\n",
    "    params = {\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bylevel': [0.1, 0.5, 1.0],\n",
    "            'max_depth': [5, 7, 16],\n",
    "            'learning_rate': [0.1, 0.5],\n",
    "            'n_estimators': [50, 200, 1000]\n",
    "            }\n",
    "    randomized_search_result = cvmodel.randomized_search(params, X=X_train, y=y_train, cv=5, n_iter=20)\n",
    "    bestmodel = CatBoostClassifier(scale_pos_weight=labelcount[0]/labelcount[1], \n",
    "                               objective='Logloss', eval_metric='AUC:hints=skip_train~false', verbose=50, \n",
    "                                early_stopping_rounds=50, **randomized_search_result['params'])\n",
    "    return bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e779b750-6f5e-4942-afe4-e53140887a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runxgboost(site, year, stg, fs, oversample, model_type):\n",
    "    print('Running '+model_type+' on site '+site+\":\"+str(year)+\":\"+stg+\":\"+fs+\":\"+oversample, flush = True)\n",
    "    \n",
    "    #load tables\n",
    "    X_train = pd.read_pickle('data/'+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "    X_test =  pd.read_pickle('data/'+site+ '/X_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "    y_train = pd.read_pickle('data/'+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "    y_test =  pd.read_pickle('data/'+site+ '/y_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "\n",
    "    tic = time.perf_counter()     \n",
    "    #xgboost\n",
    "    if model_type == \"xgbhgs\":\n",
    "        bestmodel = xgbHalvingGridSearchCV(X_train, y_train)\n",
    "        bestmodel.set_params(n_jobs=23)\n",
    "    if model_type == \"xgbbs\":        \n",
    "        bestmodel = xgbBayesSearchCV(X_train, y_train)\n",
    "        bestmodel.set_params(n_jobs=23)\n",
    "\n",
    "    #catboost\n",
    "    if model_type == \"catd\":\n",
    "        bestmodel = catDefault(X_train, y_train)\n",
    "    if model_type == \"catr\":\n",
    "        bestmodel = catRandomSearch(X_train, y_train)\n",
    "\n",
    "    print('Training xgb/cat on site '+site+\":\"+str(year)+\":\"+stg+\":\"+fs+\":\"+oversample, flush = True)\n",
    "    bestmodel.fit(X_train, y_train, eval_set=[(X_train, y_train)], verbose=50, early_stopping_rounds=50)\n",
    "    prelabel = bestmodel.predict(X_test)\n",
    "    print('roc = '+ str(roc_auc_score(y_test, prelabel)))    \n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print('Finished '+model_type+' on site '+site+\":\"+str(year)+\":\"+stg+\":\"+fs+\":\"+oversample, flush = True)    \n",
    "    \n",
    "    print(f\"{site}:{year}:{stg}:{fs}:{oversample}: finished in {toc - tic:0.4f} seconds\")  \n",
    "    pickle.dump(bestmodel, open('data/'+site+'/model_'+model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl', 'wb'))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
